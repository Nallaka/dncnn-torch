{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model = \"DnCNN\"\n",
    "batch_size = 128\n",
    "train_path = \"\"\n",
    "test_path = \"\"\n",
    "noise_level = 15\n",
    "n_epoch = 180\n",
    "learning_rate = 1e-3\n",
    "\n",
    "patch_size = 40\n",
    "stride = 10\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "save_path = os.path.join('models', f\"{model}_sigma{noise_level}\")\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def load_train(train_path):\n",
    "    images = []\n",
    "\n",
    "    train_set = glob.glob(train_path + '/*.jpg')\n",
    "    print(f\"Train Set: {len(train_set)} images\")\n",
    "\n",
    "    for i in range(len(train_set)):\n",
    "        image = cv2.imread(train_set[i], 0)\n",
    "        images.append(image)\n",
    "\n",
    "    print(f\"{len(images)} images loaded\")\n",
    "\n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def load_test(test_path):\n",
    "    images = []\n",
    "\n",
    "    test_set = glob.glob(test_path + '/*.jpg')\n",
    "    print(f\"Test Set: {len(test_set)} images\")\n",
    "\n",
    "    for i in range(len(test_set)):\n",
    "        image = cv2.imread(test_set[i], 0)\n",
    "        images.append(image)\n",
    "\n",
    "    print(f\"{len(images)} images loaded\")\n",
    "    \n",
    "    return images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def gen_patches(img):\n",
    "    h, w = img.shape\n",
    "\n",
    "    patches = []\n",
    "\n",
    "    for i in range(0, h - patch_size + 1, stride):\n",
    "        for j in range(0, w - patch_size + 1, stride):\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            patches.append(patch)\n",
    "\n",
    "    return patches"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def gen_data(images):\n",
    "    data = []\n",
    "\n",
    "    for img in images:\n",
    "        patches = gen_patches(img)\n",
    "        for patch in patches:\n",
    "            data.append(patch)\n",
    "\n",
    "    data = np.array(data, dtype='uint8')\n",
    "    data = np.expand_dims(data, axis=3)\n",
    "\n",
    "    discard = len(data)-len(data)// batch_size*batch_size\n",
    "\n",
    "    data = np.delete(data, range(discard), axis=0)\n",
    "\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set: 200 images\n",
      "200 images loaded\n"
     ]
    }
   ],
   "source": [
    "images = load_train(\"train_set\")\n",
    "data = gen_data(images)\n",
    "#print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DnDataset(Dataset):\n",
    "    def __init__(self, patches, sigma):\n",
    "        super(DnDataset, self).__init__()\n",
    "        self.patches = patches\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.patches[idx]\n",
    "        noise = torch.randn(batch_x.size()).mul_(self.sigma / 255.0)\n",
    "        batch_y = batch_x + noise\n",
    "        return batch_y, batch_x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.patches.size(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, depth=17, n_channels=64, images_channels=1, bnorm=True, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "\n",
    "        padding = 1\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels=images_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding,\n",
    "                      bias=True), nn.ReLU(inplace=True)]\n",
    "\n",
    "        for i in range(depth - 2):\n",
    "            layers.append(\n",
    "                nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding,\n",
    "                          bias=False))\n",
    "            layers.append(nn.BatchNorm2d(n_channels, eps=0.0001, momentum=0.95))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        layers.append(\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=images_channels, kernel_size=kernel_size, padding=padding,\n",
    "                      bias=False))\n",
    "\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        out = self.dncnn(x)\n",
    "        return y - out\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                init.orthogonal_(module.weight)\n",
    "\n",
    "                if module.bias is not None:\n",
    "                    init.constant_(module, 0)\n",
    "\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                init.constant_(module.weight, 1)\n",
    "                init.constant_(module.bias, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = DnCNN()\n",
    "\n",
    "model.train()\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "scheduler = MultiStepLR(optimizer, milestones=[30,60,90], gamma=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(0, n_epoch):\n",
    "    scheduler.step(epoch)\n",
    "    images = load_train(\"train_set\")\n",
    "    xs = gen_data(images)\n",
    "    xs = xs.astype('float32')/255.0\n",
    "    xs = torch.from_numpy(xs.transpose((0,3,1,2)))\n",
    "    DnDataset = DnDataset(xs, sigma=noise_level)\n",
    "    DLoader = DataLoader(dataset=DnDataset, num_workers=4, drop_last=True, batch_size=batch_size, shuffle=True)\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for n_count, batch_yx in enumerate(DLoader):\n",
    "        optimizer.zero_grad()\n",
    "        if cuda:\n",
    "            batch_x, batch_y = batch_yx[1].cuda(), batch_yx[0].cuda()\n",
    "\n",
    "        loss = criterion(model(batch_y), batch_x)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if n_count % 10 == 0:\n",
    "            print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, xs.size(0)//batch_size, loss.item()/batch_size))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}